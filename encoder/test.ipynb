{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_per_batch, utterances_per_speaker = 5, 10\n",
    "embeds = torch.rand(size=(speakers_per_batch, utterances_per_speaker, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GE2E Sim Mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(embeds):\n",
    "    \"\"\"\n",
    "    Computes the similarity matrix according the section 2.1 of GE2E.\n",
    "\n",
    "    :param embeds: the embeddings as a tensor of shape (speakers_per_batch, \n",
    "    utterances_per_speaker, embedding_size)\n",
    "    :return: the similarity matrix as a tensor of shape (speakers_per_batch,\n",
    "    utterances_per_speaker, speakers_per_batch)\n",
    "    \"\"\"\n",
    "    similarity_weight = nn.Parameter(torch.tensor([10.]))\n",
    "    similarity_bias = nn.Parameter(torch.tensor([-5.]))\n",
    "\n",
    "    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n",
    "    \n",
    "    # Inclusive centroids (1 per speaker). Cloning is needed for reverse differentiation\n",
    "    centroids_incl = torch.mean(embeds, dim=1, keepdim=True)\n",
    "    centroids_incl = centroids_incl.clone() / (torch.norm(centroids_incl, dim=2, keepdim=True) + 1e-5)\n",
    "\n",
    "    # Exclusive centroids (1 per utterance)\n",
    "    centroids_excl = (torch.sum(embeds, dim=1, keepdim=True) - embeds)\n",
    "    centroids_excl /= (utterances_per_speaker - 1)\n",
    "    centroids_excl = centroids_excl.clone() / (torch.norm(centroids_excl, dim=2, keepdim=True) + 1e-5)\n",
    "\n",
    "    # Similarity matrix. The cosine similarity of already 2-normed vectors is simply the dot\n",
    "    # product of these vectors (which is just an element-wise multiplication reduced by a sum).\n",
    "    # We vectorize the computation for efficiency.\n",
    "    sim_matrix = torch.zeros(speakers_per_batch, utterances_per_speaker,\n",
    "                                speakers_per_batch)\n",
    "    mask_matrix = 1 - np.eye(speakers_per_batch, dtype=int)\n",
    "    for j in range(speakers_per_batch):\n",
    "        # each row in mask_matrix represents 1 speaker in batch\n",
    "        mask = np.where(mask_matrix[j])[0] # indexes of 1s in mask_matrix\n",
    "        # compute cosine sim via dot product\n",
    "        sim_matrix[mask, :, j] = (embeds[mask] * centroids_incl[j]).sum(dim=2)\n",
    "        sim_matrix[j, :, j] = (embeds[j] * centroids_excl[j]).sum(dim=1)\n",
    "       \n",
    "    sim_matrix = sim_matrix * similarity_weight + similarity_bias\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GE2E Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_ge2e_loss(embeds):\n",
    "    \"\"\"\n",
    "    Computes the softmax loss according the section 2.1 of GE2E.\n",
    "    \n",
    "    :param embeds: the embeddings as a tensor of shape (speakers_per_batch, \n",
    "    utterances_per_speaker, embedding_size)\n",
    "    :return: the loss and the EER for this batch of embeddings.\n",
    "    \"\"\"\n",
    "    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Loss\n",
    "    sim_matrix = similarity_matrix(embeds)\n",
    "    temp = sim_matrix\n",
    "    sim_matrix = sim_matrix.reshape((speakers_per_batch * utterances_per_speaker,  \n",
    "                                        speakers_per_batch))\n",
    "    ground_truth = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n",
    "    target = torch.from_numpy(ground_truth).long()\n",
    "    loss = ce_loss(sim_matrix, target)\n",
    "    \n",
    "    # EER (not backpropagated)\n",
    "    with torch.no_grad():\n",
    "        inv_argmax = lambda i: np.eye(1, speakers_per_batch, i, dtype=int)[0]\n",
    "        labels = np.array([inv_argmax(i) for i in ground_truth])\n",
    "        preds = sim_matrix.detach().cpu().numpy()\n",
    "\n",
    "        # Snippet from https://yangcha.github.io/EER-ROC/\n",
    "        fpr, tpr, thresholds = roc_curve(labels.flatten(), preds.flatten())           \n",
    "        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 10])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joon_ge2e_loss(x):\n",
    "    \n",
    "    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n",
    "    w = nn.Parameter(torch.tensor(10.0))\n",
    "    b = nn.Parameter(torch.tensor(-5.0))\n",
    "    criterion  = nn.CrossEntropyLoss()\n",
    "\n",
    "    assert x.size()[1] >= 2\n",
    "\n",
    "    gsize = x.size()[1] # utterances per speaker\n",
    "    centroids = torch.mean(x, 1) # inc centroids without norm\n",
    "    stepsize = x.size()[0] # speakers per batch\n",
    "\n",
    "    cos_sim_matrix = []\n",
    "\n",
    "    for ii in range(0,gsize): \n",
    "        idx = [*range(0,gsize)]\n",
    "        idx.remove(ii)\n",
    "        exc_centroids = torch.mean(x[:,idx,:], 1)\n",
    "        cos_sim_diag    = F.cosine_similarity(x[:,ii,:],exc_centroids)\n",
    "        cos_sim         = F.cosine_similarity(x[:,ii,:].unsqueeze(-1),centroids.unsqueeze(-1).transpose(0,2))\n",
    "        cos_sim[range(0,stepsize),range(0,stepsize)] = cos_sim_diag\n",
    "        cos_sim_matrix.append(torch.clamp(cos_sim,1e-6))\n",
    "    temp = cos_sim_matrix\n",
    "    cos_sim_matrix = torch.stack(cos_sim_matrix,dim=1)\n",
    "    \n",
    "    torch.clamp(w, 1e-6)\n",
    "    cos_sim_matrix = torch.tensor(cos_sim_matrix)\n",
    "    cos_sim_matrix = cos_sim_matrix * w + b\n",
    "    \n",
    "\n",
    "    ground_truth = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n",
    "    target = torch.from_numpy(ground_truth).long()\n",
    "\n",
    "    label   = torch.from_numpy(np.asarray(range(0,stepsize)))\n",
    "    nloss = criterion(cos_sim_matrix.view(-1,stepsize), target)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     inv_argmax = lambda i: np.eye(1, speakers_per_batch, i, dtype=int)[0]\n",
    "    #     labels = np.array([inv_argmax(i) for i in ground_truth])\n",
    "    #     preds = sim_matrix.detach().cpu().numpy()\n",
    "\n",
    "    #     # Snippet from https://yangcha.github.io/EER-ROC/\n",
    "    #     fpr, tpr, thresholds = roc_curve(labels.flatten(), preds.flatten())           \n",
    "    #     eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    return label, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8616, 0.8481, 0.8584, 0.8956, 0.8388],\n",
       "        [0.8352, 0.8375, 0.8238, 0.8065, 0.8069],\n",
       "        [0.8888, 0.8414, 0.8727, 0.8883, 0.9196],\n",
       "        [0.7981, 0.7690, 0.7929, 0.8008, 0.7798],\n",
       "        [0.8443, 0.8539, 0.8443, 0.8443, 0.8568]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_anchor = torch.mean(embeds[:,1:,:], 1)\n",
    "out_pos = embeds[:,0,:]\n",
    "step = out_anchor.size()[0]\n",
    "cos_sim_matrix  = F.cosine_similarity(out_pos.unsqueeze(-1),out_anchor.unsqueeze(-1).transpose(0,2))\n",
    "cos_sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 20]), torch.Size([5, 20]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_anchor.shape, out_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry\\AppData\\Local\\Temp/ipykernel_13184/3498039839.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cos_sim_matrix = torch.tensor(cos_sim_matrix)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4], dtype=torch.int32),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joon_ge2e_loss(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemat = similarity_matrix(embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angular Proto Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_proto_loss(embeds, init_w = 10.0, init_b = -5.0, label=None):\n",
    "    \"\"\"Computes angular variant of prototypical loss.\n",
    "\n",
    "    Args:\n",
    "        embeds : \n",
    "        label (_type_, optional): _description_. Defaults to None.\n",
    "    \"\"\"\n",
    "    assert embeds.size()[1] >= 2\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    w = nn.Parameter(torch.tensor(init_w))\n",
    "    b = nn.Parameter(torch.tensor(init_b))\n",
    "\n",
    "    out_anchor = torch.mean(embeds[:,1:,:], 1)\n",
    "    out_pos = embeds[:,0,:]\n",
    "    step = out_anchor.size()[0]\n",
    "\n",
    "    sim_matrix = F.cosine_similarity(out_pos.unsqueeze(-1),out_anchor.unsqueeze(-1).transpose(0,2))\n",
    "    torch.clamp(w, 1e-6)\n",
    "    sim_matrix = sim_matrix * w + b\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4136, 4.2625, 3.2234, 4.1107, 4.1484],\n",
       "        [3.7012, 4.0986, 3.7119, 3.8583, 3.7990],\n",
       "        [3.0190, 2.9903, 3.0917, 2.7785, 2.8525],\n",
       "        [3.6497, 3.8180, 3.3977, 3.7257, 3.7587],\n",
       "        [3.5589, 3.3426, 3.7194, 3.9845, 3.8502]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix = angular_proto_loss(embeds)\n",
    "sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n",
    "centroids_incl = torch.mean(embeds, dim=1, keepdim=True)\n",
    "centroids_incl = centroids_incl.clone() / (torch.norm(centroids_incl, dim=2, keepdim=True) + 1e-5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4236b1bd8af5c88b200f8ae259f28c355fd90bec7f49eb3a4c44b52c2fc9f9b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
